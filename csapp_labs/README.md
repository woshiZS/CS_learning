## 读书笔记

### Chapter 3 Machine Level Representation
> 算是随便记录的一点笔记，开始想记这个笔记的时候已经看到第三章了

* 完成condition branch那里比较有意思，一种更有效率的做法是conditional move instruction，就是条件转移，这样相较于conditional jump来说更有效率。(指令流水线的原因，condition jump会可能发生预测错误，但是是conditional data move指令执行不依赖于数据，conditional move实现的具体细节会在后面章节里面讲到)
* 参数寄存器：rdi, rsi, rdx, rcx，先后顺序用该是反过来的，因为参数压栈是从右往左
* lea指令不会设置condition code.
* loop算是由普通指令和conditional jump指令一起实现的
* 中间循环算是跳过很多内容没有记笔记了，主要还是循环那一块的内容，包括循环转化为汇编的几种格式。熟悉一下即可，帮助不是很大。
* 之后讲了一下，数组在汇编中的表示形式，包括iso c99引入动态维度的静态数组。
* 另外就是结构体，其实也是指针做一个偏移运算，重点还是内存对齐(padding)，另外讲了一点union的好处--节省内存。
* union的另外一个作用就是在获取相同的bit representation，比如在将double转化为unsigned long的时候，如果使用的是强制转型，转化之后的字节表示可能会有非常大的不同，但是使用union的话，可以将double储存到union的一个field，然后再访问另外一个field即可。
* 另外讲了两个无符号整形存储在一个union的时候要注意编址方式，注意一点，大端是按照正常人的顺序来存储的，小端存储与人的直觉相反。
* 对于内置类型来说，大小为K字节的object的地址必须是K的整数倍，所有的数据对齐都是基于这个原则，为什么int, char, int中间的char要补三个字节，原因就是不补充的话，我们是没法做到让前后两个int地址同时是四的倍数。
* 缓冲区溢出以及解决方案
* address space stack randomization, 攻击者的应对手段可以不断暴力枚举，nop sled来破解
* 第三种方式就是限制memory 权限，刚开始read和execute权限用的一个bit flag，之后amd为execute引入了独立的flag，后来英特尔也进行了效仿。
* 主要来说，应对缓冲区溢出攻击比较常见的就是这三种方法


* Control transfer，指导call和ret指令做的事情分别是把rip的内容压栈和pop即可。
* 注意参数传递，个数超过6个需要压栈，压栈的顺序需要注意。

![image-20210828164727176](./img/parameter_order.png)

这里的top指的是地址最低的那个，相当于说超过第6个参数之后，需要反向压栈，使得第七个参数是最后一个压栈的（每个压栈的参数都会占用8字节的空间）。

* 参数压栈结束之后才会压返回地址。还有一些细节是关于内存对齐，这一点可以去看3.33的图片
* caller-saved && callee-saved：后者使用必须要先压栈保存原来寄存器中的值。

**Combining Control and Data in Machine-Level Programs**

* 指针类型转换的一大作用就是改变指针运算的scaling
* 函数指针的例子

```c
int fun(int x, int *p);
int (*fp)(int, int *);
fp = fun;
int y = 1;
int result = fp(3, &y);
```

函数指针的值就是这个函数第一句machine code的地址。函数指针在声明的时候必须加括号，不然就成了普通的函数原型声明。

* 关于缓冲区溢出攻击，前面提到在参数数量大于6个的时候，会先压栈参数（从右边往左边压栈），最后才把返回地址压栈，相当于缓冲区溢出最先影响的是返回地址。





### 程序性能优化

> 去除多余代码，编写利于编译器优化的代码，重构代码也是很有必要的
(写到这里的时候，公司那边已经写了一点了，估计要等后期merge才能整合到一块了).

* C编译器无法事先确定代码中是否有内存应用，所以每次进行内存的读写时，他是不会对内存读写做临时变量的优化的。
  * 要了解底层处理器设计，可以选修ECE 741这门课程
* 除法对于任何机器而言都是一项比较昂贵的操作
* 之后有讲到数据依赖导致指令无法并行执行，此时引入了循环展开的操作
* 除了考虑数据依赖之外，吞吐量也会导致并行效率（一般由于硬件造成），比如说机器有两个乘法单元，但是加载单元只有一个，所以实际上没法充分利用多个乘法单元的优势。课程视频中也有提到一次加载两个数据，然后就可以同时使用两个乘法单元的例子（具体细节还是要去看书）。


* 预计算值，本地缓存，避免多次寻址或者计算 
* 将乘法改成移位运算，乘法运算需要利用三个CPU时钟周期，有时候可以用加法代替就尽量不要用乘法（比如计算一个像素值相邻位置的像素值，可以先进性一此乘法运算，再做四次加法运算 

* 另外开始讲了一个例子，每次循环调用一次strlen那个例子，提醒将循环边界先缓存，避免每次都去计算产生额外的时间开销

```c
// Bad Example
void lower(char *s){
    size_t i = 0;
    for(i = 0; i < strlen(s); ++i)
        if(s[i] >= 'A' && s[i] <= 'Z')
            s[i] -= ('A' - 'a');
}
```

编译器不会对这种情况进行预先计算的编译优化，c的每个文件都是独立编译的，编译器是不确定到底是用哪一个版本的strlen

* Memory Matters

多用缓存，不要直接使用变量或者数组地址，这样每次操作都会在寄存器和内存之间移动数据，时间开销会非常大。



* 处理器架构理解
  * 实际指令执行可能和汇编程序中所显示的顺序查边很大，这就是所谓的指令乱序。
  * 两个bound，latency bound(数据依赖有关)， throughput bound: 最终决定性能上限的点
  * ICU和EU
  * 除法操作无法被pipelined，完成一个之后才能开始下一个，相对来说是一个开销比较高昂的操作	
  * critical data flow，数据依赖关系，耗时最长的data flow决定了一个loop的时间下限（而且是理论最小值）实际时间可能会在这个基准上更大一点。
